You are an expert global optimizer, helping me find the global maximum of a mathematical function f(params).
Your goal is to propose parameter values that efficiently lead us to the global maximum within a limited number of iterations (400). 

# Regarding the parameters **params**:
**params** is an array of {{ rank }} float numbers.
**params** values are in the range of [-6.0, 6.0].
You may use at least 1 decimal place, and you are allowed to use more decimal places when performing fine-grained search (e.g., 0.5, 0.25, 0.05, 0.01). Avoid scientific notation (write 0.0001 instead of 1e-4).

# Here's how we'll interact:
1. I will provide the results of previous iterations in <previous param and f(param) pairs> and the maximum number of iterations.
2. Based on the results of previous iterations and following the strategy in <Optimization Strategy> you will provide your response in the following exact format:
    * Line 1: reason over how to make the next guess (e.g., “Trying an unexplored corner”, “Moving inward by step {{ step_size }} from a boundary”, or “Fine-tuning around the best params with a very small step”).
    * Line 2: a new set of parameters 
      'params[0]: v0; params[1]: v1; params[2]: v2; ..., params[{{ rank - 1 }}]: v{{ rank - 1 }}; NEW: <flag>'
      aiming to maximize the function's value f(params), where `<flag>` is either `yes` or `no -> fallback applied`.
    Please propose params values in the range of [-6.0, 6.0].
3. In the next iteration you will get the results of function's value f(params) at that point, and produce a better guess based on that.
4. We will repeat steps 2–3 until we reach the maximum number of iterations.

# Remember:
1. **CRITICAL: Do not propose previously seen params.** Check the list above – if your proposed params appear anywhere in the data (all coordinates equal), reject them and choose different values.
2. **The global optimum should be around {{ optimum }}.** Use this only as a sense of scale for how large rewards can be, not as a hard threshold.
3. Search both positive and negative values.
4. In the beginning, explicitly try **corner points** (coordinates near ±6.0).
5. After corners are sufficiently explored, **move inward from the boundaries using step size {{ step_size }}**.
6. Once you find a **promising region** (significantly higher rewards than most points), **shrink the step size** and perform fine-grained local search with smaller increments derived from {{ step_size }} (e.g., {{ step_size }}/2, {{ step_size }}/5, {{ step_size }}/10, {{ step_size }}/100).


<Optimization Strategy>

# Analysis: Before Proposing, Summarize the Data (DO NOT PRINT)
Before choosing the next params, internally determine:
- Total evaluations.
- Number of unique parameter combinations.
- The optimization stage that you're in
- Best reward so far (best_reward) and its params (best_params).
- Reward range [min_reward, max_reward].
- The most-repeated params in the last 20 iterations.
Use it to guide your choice.

---

# Three-Stage Optimization Strategy

You should structure your search into **three stages**:

1. **Stage A – Corner Exploration** (early iterations).
2. **Stage B – Inward Grid Search with step {{ step_size }}**.
3. **Stage C – Fine Search in a Promising Region (smaller than {{ step_size }} steps)**.

You decide which stage to follow based on the iteration index {{ step_number }} and the reward patterns.

---

## Stage A – Corner Exploration (typically iterations 0–20, conceptually “early”)

Goal: explicitly probe the corners of the parameter space to understand behavior at extremes.

- A “corner” is any params where **each dimension is near either +6.0 or -6.0**.
- In this stage, you should:
  - Propose params where each coordinate is close to +6.0 or -6.0.
  - Systematically vary the sign pattern across dimensions to cover many distinct corners.
  - Avoid repeating the exact same corner vector: if a particular corner has already been tried, do not propose it again.
- You should aim to test several distinct corners (different sign patterns) early in the search.

**Transition out of Stage A:**
- Once you have tried multiple distinct corner patterns, or you observe that corners consistently yield low rewards compared to some interior points, you should **stop proposing new corners** and move to Stage B.

---

## Stage B – Inward Grid Search with step size {{ step_size }}

Goal: move from the boundaries toward the interior using increments of **{{ step_size }}**, exploring “shells” between corners and the center.

In this stage:

- Treat ±6.0 and other boundary values as starting points.
- Propose new params by moving **inward** from these boundaries in increments of {{ step_size }} on one or more dimensions:
  - For example, if {{ step_size }} = 1.0:
    - From +6.0 you can move to +5.0, +4.0, ...
    - From -6.0 you can move to -5.0, -4.0, ...
- Construct candidates by:
  - Starting from a corner or from a previously evaluated boundary point.
  - Adjusting one or more coordinates by ±{{ step_size }} so that you visit new combinations like:
    - (5.0, -5.0, 6.0, -4.0, 3.0), or
    - (-4.0, 2.0, -5.0, 1.0, -6.0), etc.
- Ensure that over time you:
  - Explore points that are not all at the edges; at least some coordinates should move into the interior (for example, between -4.0 and 4.0).
  - Cover diverse combinations instead of repeating a small set of patterns.

While in Stage B, you should:
- Still avoid any exact param vector that has already been seen.
- Pay attention to which regions improve reward: if some inward moves start yielding significantly higher f(params), mark that region as “promising”.

**Transition to Stage C:**
- When you have identified a **promising region** (one or more params with noticeably higher rewards than the typical ones), switch to Stage C and focus on fine search around that area.

---

## Stage C – Fine Search in a Promising Region (smaller than {{ step_size }})

Goal: once a promising region is identified, reduce the step size and perform a fine-grained local search around the best params.

### Identifying a promising region:

Consider a region “promising” if:
- One or more params achieve rewards that are **clearly higher** than most other evaluated points so far, or
- You see a small cluster of nearby params (similar coordinates) that all give relatively high rewards.

Let **best_params** be the current highest-reward params.

### How to propose in Stage C:

- Start conceptually from best_params.
- Change only 1–3 dimensions at a time.
- Use step sizes **smaller than {{ step_size }}**, derived from {{ step_size }}:
  - Initially, use steps on the order of {{ step_size }}/2 or {{ step_size }}/5 (e.g., 0.5, 0.2 if {{ step_size }} = 1.0).
  - If several proposals with such steps result in minor changes or small improvements, shrink the step size further:
    - Try steps like {{ step_size }}/10, {{ step_size }}/20, {{ step_size }}/100 (e.g. 0.1, 0.05, 0.01).
  - If needed, you may reduce further (e.g., 0.005, 0.001), as long as params remain within [-6.0, 6.0].
- You are allowed to use more than 1 decimal place for fine search (for example, 0.25, 0.05, 0.01, 0.005).
- Do **not** coarsely round small steps back to {{ step_size }} unless that is your deliberate choice:
  - For example, if you decide on a step of 0.05 in one dimension, you should output that value (not 0.1 or 0.0).

### Escaping local traps in Stage C:

- If many small-steps around best_params yield very similar rewards with no meaningful improvement:
  - Temporarily increase your step size (e.g., back to {{ step_size }} or {{ step_size }}/2 in one or more dimensions) to jump out of the local basin.
  - After the jump, if a new region becomes more promising, resume fine search around the updated best_params using smaller steps again.

---

# Uniqueness Enforcement (REQUIRED)

Before finalizing your proposal: check it exactly against the listed param pairs (match all coordinates).

- **If UNIQUE**:  
  Use this candidate and output it in Line 2 with `NEW: yes` appended exactly at the end.

- **If DUPLICATE**:  
  Apply this fallback immediately:
  - Increment `params[0]` by {{ step_size }}.
  - If this makes `params[0]` exceed +6.0, wrap it to -6.0.
  - If this new vector is still a duplicate, repeat this increment/wrap procedure until you obtain a unique vector.
  - Use this fallback candidate and output it in Line 2 with `NEW: no -> fallback applied` appended exactly at the end.

---

# Decision Point – Avoid Repeated Local Optima

If you notice the same or very similar parameters repeated many times in the data above, especially in the last 20 iterations, and the reward is not improving meaningfully, then you are exploring a local optimum repeatedly.

In that case:
- Intentionally break the pattern by proposing params that are clearly different from what has been tried:
  - Change at least a few dimensions significantly (by at least {{ step_size }}, or more if needed).
  - Avoid rediscovering the same cluster of points.
- After exploring this new region, if it leads to a better best_params, continue with Stage B or Stage C behavior centered around that new best_params.

</Optimization Strategy>


Next, you will see examples of params and f(params) pairs.
These are parameter values along with their evaluation value. First 20 are warmup iterations and the rest are your attempts at finding optimum values of parameters.
The warmup iterations show the real results for the parameters values in the warmup iterations.
<previous param and f(param) pairs>
{{ episode_reward_buffer_string }}
</previous param and f(param) pairs>

Now you are at iteration {{ step_number }} out of 400. Please provide the results in the indicated format. Do not provide any additional text.
